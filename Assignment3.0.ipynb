{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Network in Keras\n",
    "We will use simple data of mobile price range classifier. The dataset consists of 20 features and we need to predict the price range in which phone lies. These ranges are divided into 4 classes.\n",
    "<br>\n",
    "Dataset - https://www.kaggle.com/iabhishekofficial/mobile-price-classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataset import\n",
    "file_path = r\"amazon.csv\"\n",
    "dataset = pd.read_csv(file_path, encoding=\"iso-8859-1\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"amazon.csv\"\n",
    "amazon_df = pd.read_csv(file_path, encoding=\"iso-8859-1\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "amazon_df.head()\n",
    "\n",
    "\n",
    "# Checking for missing values\n",
    "missing_values = amazon_df.isnull().sum()\n",
    "\n",
    "# Checking for duplicates\n",
    "duplicates = amazon_df.duplicated().sum()\n",
    "\n",
    "missing_values, duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert price and discount percentage columns to numeric\n",
    "def convert_to_numeric(column):\n",
    "    return pd.to_numeric(column.str.replace('[^0-9.]', '', regex=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'discounted_price', 'actual_price', and 'discount_percentage' to numeric\n",
    "amazon_df['discounted_price'] = convert_to_numeric(amazon_df['discounted_price'])\n",
    "amazon_df['actual_price'] = convert_to_numeric(amazon_df['actual_price'])\n",
    "amazon_df['discount_percentage'] = convert_to_numeric(amazon_df['discount_percentage'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-numeric entries in 'rating' with NaN and then convert to numeric\n",
    "# You can also use 'mean', 'median', or any other statistical measure if you don't want to use NaN\n",
    "amazon_df['rating'] = pd.to_numeric(amazon_df['rating'], errors='coerce')\n",
    "\n",
    "# If you want to remove rows with non-numeric 'rating' instead of replacing with NaN\n",
    "# amazon_df = amazon_df[pd.to_numeric(amazon_df['rating'], errors='coerce').notna()]\n",
    "\n",
    "# Convert 'rating_count', handling commas and coercing errors\n",
    "amazon_df['rating_count'] = pd.to_numeric(amazon_df['rating_count'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# Rechecking the data types after conversion\n",
    "updated_data_types = amazon_df.dtypes\n",
    "\n",
    "updated_data_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying non-numeric entries in the 'rating' column\n",
    "\n",
    "# Convert 'rating' column to string\n",
    "amazon_df['rating'] = amazon_df['rating'].astype(str)\n",
    "\n",
    "# Identifying non-numeric entries in the 'rating' column\n",
    "non_numeric_ratings = amazon_df[~amazon_df['rating'].str.replace('.', '', regex=True).str.isnumeric()]['rating']\n",
    "\n",
    "non_numeric_ratings.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows where 'rating' contains '|'\n",
    "amazon_df = amazon_df[amazon_df['rating'] != '|']\n",
    "\n",
    "# Converting 'rating' to numeric\n",
    "amazon_df['rating'] = pd.to_numeric(amazon_df['rating'], errors='coerce')\n",
    "\n",
    "# Recheck the data types after conversion\n",
    "updated_data_types = amazon_df.dtypes\n",
    "\n",
    "updated_data_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any missing values\n",
    "amazon_df = amazon_df.dropna()\n",
    "\n",
    "# Check the updated dataset for missing values\n",
    "updated_missing_values = amazon_df.isnull().sum()\n",
    "updated_missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = amazon_df['category'].str.split('|').explode()\n",
    "unique_categories = categories.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_categories = len(unique_categories)\n",
    "print(number_of_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.drop('about_product', axis=1, inplace=True)\n",
    "amazon_df.drop('review_id', axis=1, inplace=True)\n",
    "amazon_df.drop('user_id', axis=1, inplace=True)\n",
    "amazon_df.drop('product_name', axis=1, inplace=True)\n",
    "amazon_df.drop('user_name', axis=1, inplace=True)\n",
    "# amazon_df['user_id'] = amazon_df['user_id'].astype('category')\n",
    "amazon_df['product_id'] = amazon_df['product_id'].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "# amazon_df['user_id'] = amazon_df['user_id'].cat.codes\n",
    "amazon_df['product_id'] = amazon_df['product_id'].cat.codes\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to apply sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    # Ensure text is a string\n",
    "    text = str(text)\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "# Apply the sentiment analysis function to the text data column\n",
    "# Replace 'review_content' with your actual text data column name\n",
    "amazon_df['sentiment'] = amazon_df['review_content'].apply(get_sentiment)\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.drop('review_content', axis=1, inplace=True)\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.drop('review_title', axis=1, inplace=True)\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.drop('img_link', axis=1, inplace=True)\n",
    "amazon_df.drop('product_link', axis=1, inplace=True)\n",
    "amazon_df.drop('sales', axis=1, inplace=True)\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df.fillna({\n",
    "    'discounted_price': amazon_df['discounted_price'].mean(),\n",
    "    'actual_price': amazon_df['actual_price'].mean(),\n",
    "    'discount_percentage': amazon_df['discount_percentage'].mean(),\n",
    "    'rating': amazon_df['rating'].mean(),\n",
    "    'rating_count': amazon_df['rating_count'].mean()\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df['price_difference'] = amazon_df['actual_price'] - amazon_df['discounted_price']\n",
    "amazon_df['has_discount'] = amazon_df['discount_percentage'].apply(lambda x: 1 if x > 0 else 0)\n",
    "amazon_df['rating_level'] = pd.cut(amazon_df['rating'], bins=[0, 2, 4, 5], labels=[0, 1,2 ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_data = amazon_df['category'].str.get_dummies(sep='|')\n",
    "\n",
    "df = amazon_df.join(one_hot_encoded_data)\n",
    "\n",
    "# 刪除原始的 'category' 列\n",
    "df.drop('category', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['discounted_price', 'actual_price', 'discount_percentage', 'rating', 'rating_count']  # Add other numerical columns if needed\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=[\"rating\",\"rating_count\"]).values\n",
    "\n",
    "y =  df[[\"rating\",\"rating_count\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df[[\"rating\",\"rating_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "print('Normalized data:')\n",
    "print(X[0])\n",
    "\n",
    "# One hot encode\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder()\n",
    "# y = ohe.fit_transform(y).toarray()\n",
    "# print('One hot encoded array:')\n",
    "# print(y[0:5])\n",
    "\n",
    "# Train test split of model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = keras.models.load_model('models/myhomeworkModel2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(len(X[0]), input_dim=len(X[0]), activation='relu'))  # Adjusted input_dim to match data shape\n",
    "model.add(Dense(len(X[0])/2, activation='relu'))\n",
    "model.add(Dense(len(X[0])/2, activation='relu'))\n",
    "# model.add(Dense(len(X[0])/2, activation='relu'))\n",
    "model.add(Dense(len(X[0])/4, activation='relu'))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize neural network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred, test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using test data as validation data\n",
    "history1 = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([ 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/myhomeworkModel2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your trained ANN model\n",
    "# 'X_test' is your test dataset\n",
    "\n",
    "# Create a copy for manipulation\n",
    "X_test_modified = X_test.copy()\n",
    "\n",
    "# Increase ratings in the test data\n",
    "# Assuming 'rating' column index is known\n",
    "X_test_modified[:, rating_col_index] += rating_increase  # e.g., increase by 0.5 or 1\n",
    "\n",
    "# Predict sales with increased ratings\n",
    "predicted_sales_with_higher_ratings = model.predict(X_test_modified)\n",
    "\n",
    "# Calculate percentage change in sales\n",
    "percentage_change = ((predicted_sales_with_higher_ratings - original_sales) / original_sales) * 100\n",
    "\n",
    "# Print the average percentage change\n",
    "average_percentage_change = np.mean(percentage_change)\n",
    "print(f\"Average estimated increase in sales: {average_percentage_change}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}